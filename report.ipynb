{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Knowledge Distillation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом ноутбуке содержится описание моих основных экспериментов по knowledge distillation. Здесь будут в основном графики и описания экспериментов, весь код для обучения и оценки качества моделей вынесен в отдельные модули. Проще всего запустить в Google Colab, тогда не нужно дополнительно устанавливать никаких зависимостей. Если хотите запустить решение на своей локальной машине, то следуйте инструкциям в README.md.\n",
    "\n",
    "Выполните следующие две ячейки, если работаете в Google Colab:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! git clone github.com/stdereka/knowledge-distillation\n",
    "! cp -r knowledge-distillation/dark_knowledge/ .\n",
    "! cp -r knowledge-distillation/experiments/ ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, \"/content/knowledge-distillation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Описание задачи\n",
    "\n",
    "Метод KD был изначально предложен в [статье](https://arxiv.org/pdf/1503.02531.pdf). Для задачи многоклассовой классификации утверждается, что вероятности классов, предсказанные моделью-учителем, могут быть исползованы для обучения более простой модели-студента с меньшим числом параметров путём модификации лосса. Для многоклассовой классификации предлагается следующая функция потерь (здесь индекс $i$ пробегает по всем классам и по всем объектам):\n",
    "\n",
    "\\begin{equation}\n",
    "E=-T^{2} (1 - \\alpha) \\sum_{i} \\hat{y}_{i}(\\mathbf{x} \\mid T) \\log y_{i}(\\mathbf{x} \\mid T)- \\alpha\\sum_{i} \\bar{y}_{i} \\log y_{i}(\\mathbf{x} \\mid 1)\n",
    "\\end{equation}\n",
    "\n",
    "где $y_{i}(\\mathbf{x} \\mid T)=\\frac{e^{\\frac{z_{i}(\\mathbf{x})}{T}}}{\\sum_{j} e^{\\frac{z_{j}(\\mathrm{x})}{T}}}$ - предсказания модели при температуре $T$ (она требуется для того, чтобы предсказания сильнее отличались от 0 и 1 и несли больше информации), $\\hat{y}_{i}(\\mathbf{x} \\mid T)$ - \"мягкие\" метки учителя, $\\bar{y}_{i}$ - \"жёсткие\" groundtruth метки. $\\alpha$ - весовой параметр для регулирования вклада жёсткой и мягкой кроссэнтропий в градиент. Авторы статьи пишут, что всё должно хорошо работать при $\\alpha$ близком к нулю.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Почему Imagewoof?\n",
    "\n",
    "Imagewoof - датасет из изображений собак, относящимся к разным породам. На нём можно решать задачу многоклассовой классификации. Я выбрал его для экспериментов по нескольким причинам. Во-первых, классы трудноразделимы, слишком простые модели не смогут эффективно решить задачи, поэтому есть шансы пронаблюдать эффекты KD на более сложных моделях. Во-вторых, по Imagewoof не так много публикаций на тему KD, это значит, что результаты экспериментов мне заранее не известны.\n",
    "\n",
    "Сначала я хотел начать с воспроизведения результатов статьи на датасете MNIST, потом попробовать CIFAR-10, но это уже сделали за меня, например, [тут](https://github.com/peterliht/knowledge-distillation-pytorch). Я решил сразу начать со своих экспериментов на более сложной задаче."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Общая схема эксперимента\n",
    "\n",
    "1. **Выбрать и обучить модель-учитель.** Эта модель должна содержать большое число параметров (возможно, даже избыточное) и быть сильно регуляризована (в задачах CV подойдут сильные дропауты и аугментации), а также выдавать очень хорошее (по меркам задачи) качество на отложенной выборке.\n",
    "\n",
    "2. **Обучение и оценка качества модели-студента с Distillation Loss.** Модель-студент содержит ощутимо меньше параметров, чем модель-учитель и никак не регуляризована. На этом этапе можно играть с параметрами $\\alpha$, $T$, размером обучающей выборки и много чем ещё.\n",
    "\n",
    "3. **Обучить модель-студента без помощи учителя.** Здесь очень важно, чтобы процесс обучения отличался только лоссом, это позволит исключить вклад всех прочих факторов.\n",
    "\n",
    "4. **Сравнить метрики в пунктах 2 и 3**, построить выводы об эффективности KD в текущем эксперименте.\n",
    "\n",
    "Из бесплатных ресурсов в моём распоряженни был только Google Colab, это очень неудобно с точки зрения разработки и воспроизводимости результатов, но я смог найти выход и прийти к следующей схеме разработки. Код пишется и тестируется локально на моём компьютере. Когда всё готово, ноутбук с параметрами отправляется на Google Сolab, подтягивает код с GitHub и выполняет эксперимент. Затем код, результаты и параметры сохраняются в одном коммите, это позволяет при необходимости вернуться и воспроизвести эксперимент."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Демонстрационный эксперимент\n",
    "\n",
    "В этой части я проведу эксперимент согласно пункту 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "! wget https://s3.amazonaws.com/fast-ai-imageclas/imagewoof2-320.tgz\n",
    "! tar zxf imagewoof2-320.tgz\n",
    "# Check GPU model\n",
    "! nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from training import train, predict, DistillationLoss\n",
    "from models import *\n",
    "from datasets import Imagewoof\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on CPU\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Define globals and seed whatever I can seed\n",
    "\"\"\"\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "train_on_gpu = torch.cuda.is_available()\n",
    "if not train_on_gpu:\n",
    "    print('Training on CPU')\n",
    "    DEVICE = torch.device(\"cpu\")\n",
    "else:\n",
    "    print('Training on GPU')\n",
    "    DEVICE = torch.device(\"cuda\")\n",
    "\n",
    "SEED = 0\n",
    "seed_everything(SEED)\n",
    "\n",
    "TRAIN_DIR = Path('./imagewoof2-320/train')\n",
    "TEST_DIR = Path('./imagewoof2-320/val')\n",
    "\n",
    "train_val_files = sorted(list(TRAIN_DIR.rglob('*.JPEG')))\n",
    "test_files = sorted(list(TEST_DIR.rglob('*.JPEG')))\n",
    "\n",
    "train_val_labels = [path.parent.name for path in train_val_files]\n",
    "LABEL_ENCODER = LabelEncoder()\n",
    "LABEL_ENCODER.fit(train_val_labels)\n",
    "\n",
    "N_CLASSES = LABEL_ENCODER.classes_.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1. Выбор и обучение модели-учителя\n",
    "\n",
    "Учитель - Resnet101 с предобученными весами. Я добавил два скрытых полносвязных слоя по 2048 юнитов. Такая модель явно избыточна, очень быстро переобучается и требует адский дропаут ($p=0.95$), чтобы не переобучиться и показать хорошие результаты на валидационной выборке. При обучении этой модели я также задействовал сильные аугментации.\n",
    "\n",
    "Для дальнейших экспериментов (например, с размером обучающей выборки для модели-студента) могут понадобиться предсказания учителя на всей обучающей выборке. Чтобы не допустить утечки данных я использую 1x4 кроссвалидацию со стратификацией по классам, итоговые предсказания - это out-of-fold предсказания моделей-учителей, соответствующих разным фолдам. Таким образом, для получения предсказаний на всём датасете нужно обучить учителя целых 4 раза, зато после этого можно надолго о нём забыть и заняться непосредственно KD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_SPLITS = 4\n",
    "\n",
    "seed_everything(SEED)\n",
    "\n",
    "cv = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED)\n",
    "ground = np.array(Imagewoof(train_val_files, LABEL_ENCODER).labels)\n",
    "\n",
    "# Array for storing OOF logits\n",
    "oof_logits = np.empty((len(train_val_files), N_CLASSES), float)\n",
    "\n",
    "labels = LABEL_ENCODER.transform(train_val_labels)\n",
    "\n",
    "test_dataset = Imagewoof(test_files, LABEL_ENCODER)\n",
    "test_loader = DataLoader(test_dataset, shuffle=False, batch_size=64)\n",
    "\n",
    "# Array for storing test dataset logits\n",
    "test_logits = np.zeros((len(test_dataset), N_CLASSES), float)\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(train_val_files, labels)):\n",
    "    print('Training on fold', fold + 1)\n",
    "\n",
    "    val_dataset = Imagewoof(np.array(train_val_files)[val_idx], LABEL_ENCODER)\n",
    "    train_dataset = Imagewoof(np.array(train_val_files)[train_idx], LABEL_ENCODER, augs=True)\n",
    "    \n",
    "    model = resnet101_teacher(N_CLASSES, DEVICE)\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=0.0003)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    history = train(train_dataset, val_dataset, model=model, epochs=20,\n",
    "                              batch_size=64, device=DEVICE, opt=opt, criterion=criterion)\n",
    "    \n",
    "    val_loader = DataLoader(val_dataset, shuffle=False, batch_size=64)\n",
    "    labels_val = ground[val_idx]\n",
    "    \n",
    "    logits_val = predict(model, val_loader, DEVICE, logit=True)\n",
    "    oof_logits[val_idx] = logits_val\n",
    "    preds_val = np.argmax(logits_val, axis=1)\n",
    "    \n",
    "    # Prediction on test set is an average of N_SPLITS models\n",
    "    test_logits += predict(model, test_loader, DEVICE, logit=True)/N_SPLITS\n",
    "    \n",
    "    print(f'Fold {fold + 1} accuracy score:', accuracy_score(labels_val, preds_val))\n",
    "\n",
    "oof_preds = np.argmax(oof_logits, axis=1)\n",
    "print('OOF accuracy score:', accuracy_score(ground, oof_preds))\n",
    "\n",
    "# Save results\n",
    "os.makedirs(\"./dark_knowledge\", exist_ok=True)\n",
    "np.save(\"./dark_knowledge/resnet101_train_imagewoof.npy\", oof_logits)\n",
    "np.save(\"./dark_knowledge/resnet101_test_imagewoof.npy\", test_logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У датасета Imagewoof есть собственный [leaderboard](https://github.com/fastai/imagenette#imagewoof-leaderboard). Можно видеть, что наш учитель выдаёт неплохие результаты. Точность выше, чем у представленных моделей, так как у моей модели предобученные веса."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2. Модель-студент. Дистилляция знаний\n",
    "\n",
    "Учитель - Resnet18 с предобученными весами и двумя дополнительными скрытыми полносвязными слоями по 148 юнитов. При обучении этой модели я не задействую ни дропаут, ни аугментации. Спойлер: это необходимо, потому что эффект от KD очень маленький, и чтобы его обнаружить, нужно исключить все прочие факторы, влияющие на качество модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"./experiments/hyperparams\", exist_ok=True)\n",
    "seed_everything(SEED)\n",
    "\n",
    "resnet18 = resnet18_student2(N_CLASSES, DEVICE)\n",
    "trainable = get_number_of_params(resnet18, trainable=True)\n",
    "total = get_number_of_params(resnet18, trainable=False)\n",
    "print(f\"{trainable} (of {total}) trainable params\")\n",
    "train_dataset = Imagewoof(train_val_files, LABEL_ENCODER, teacher_labels=\"./dark_knowledge/resnet101_train_imagewoof.npy\")\n",
    "test_dataset = Imagewoof(test_files, LABEL_ENCODER, teacher_labels=\"./dark_knowledge/resnet101_test_imagewoof.npy\")\n",
    "opt = torch.optim.Adam(resnet18.parameters(), lr=0.0003)\n",
    "criterion = DistillationLoss(alpha=0.1, temperature=4.0)\n",
    "history_resnet18 = train(train_dataset, test_dataset, resnet18, 50, 64, DEVICE, opt, criterion)\n",
    "plot_training_history(history_resnet18)\n",
    "np.save(f\"./experiments/hyperparams/history_resnet18_T_4.0_alpha_0.1.npy\", history_resnet18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3. Обучение без помощи учителя и сравнение результатов\n",
    "\n",
    "Повторим процедуру предыдущего пункта, только без использования меток модели-учителя."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"./experiments/hyperparams\", exist_ok=True)\n",
    "seed_everything(SEED)\n",
    "\n",
    "seed_everything(SEED)\n",
    "resnet18 = resnet18_student2(N_CLASSES, DEVICE)\n",
    "trainable = get_number_of_params(resnet18, trainable=True)\n",
    "total = get_number_of_params(resnet18, trainable=False)\n",
    "print(f\"{trainable} (of {total}) trainable params\")\n",
    "train_dataset = Imagewoof(train_val_files, LABEL_ENCODER)\n",
    "test_dataset = Imagewoof(test_files, LABEL_ENCODER)\n",
    "opt = torch.optim.Adam(resnet18.parameters(), lr=0.0003)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "history_resnet18_no_teacher = train(train_data set, test_dataset, resnet18, 50, 64, DEVICE, opt, criterion)\n",
    "plot_training_history(history_resnet18)\n",
    "np.save(f\"./experiments/hyperparams/history_resnet18_no_teacher.npy\", history_resnet18_no_teacher)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Эксперимент с разными температурами"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Результаты и промежуточные выводы"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
